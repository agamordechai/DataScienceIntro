{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "<a id=\"home\"></a>\n",
    "![Final Lesson Exercise](images/Banner_FEX.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "# Lesson #10: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "## About this assignment\n",
    "In this assignment, you will explore [information regarding customers spendings](#dataset_desc), in order to learn learn customer segmentations.<br/>\n",
    "\n",
    "This time you will practice the clustering flow and the use of clustering algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external packages. \n",
    "\n",
    "**Use the following libraries for the assignment, when needed**:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.319623Z",
     "start_time": "2025-01-17T16:10:39.288460Z"
    }
   },
   "source": [
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# === CELL TYPE: IMPORTS AND SETUP \n",
    "\n",
    "import os                       # for testing use only\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cluster\n",
    "\n",
    "from sklearn import metrics, preprocessing, neighbors, cluster\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n",
    "# Create color maps\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap([\"#e41a1c\",\"#984ea3\",\"#a65628\",\"#377eb8\",\"#ffff33\",\"#4daf4a\",\"#ff7f00\"])"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "<a id=\"dataset_desc\"></a>\n",
    "[Go back to the beginning of the assignment](#home)\n",
    "## The mall customer information dataset\n",
    "In this assignment, you will explore information regarding customers spendings.<br/>\n",
    "**The mall customer information dataset, includes the following features**:<br/>\n",
    "* CustomerID: Unique customer ID \n",
    "* Gender: customer's gender \n",
    "* Age: customer's age\n",
    "* Annual Income (k NIS): customer's annual income\n",
    "* Customer Score (1-100): customer shopping potential score<br />\n",
    "\n",
    "[go to basic data exploration](#data_exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "## 1. Load the dataset and prepare dataset for clustering\n",
    "In this section you will perform the following actions:<br />\n",
    "* Load the mall customers dataset\n",
    "* Remove missing values\n",
    "* Remove duplicate rows\n",
    "* Transfer string to numeric\n",
    "* Scale features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.a. Instructions\n",
    "<u>method name</u>: <b>load_dataset</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'load_dataset' function to load the mall customer information dataset from the 'file_name' csv file\n",
    "  into a pandas dataframe.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return df_dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.354214Z",
     "start_time": "2025-01-17T16:10:39.330459Z"
    }
   },
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.396542Z",
     "start_time": "2025-01-17T16:10:39.387507Z"
    }
   },
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def load_dataset(file_name):\n",
    "    return pd.read_csv(file_name)\n"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.437143Z",
     "start_time": "2025-01-17T16:10:39.428652Z"
    }
   },
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.463353Z",
     "start_time": "2025-01-17T16:10:39.457886Z"
    }
   },
   "source": [
    "# 1.a. \n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test1a-1_load_dataset",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.515318Z",
     "start_time": "2025-01-17T16:10:39.492383Z"
    }
   },
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.a. - Test 1 (name: test1a-1_load_dataset, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'load_dataset' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'load_dataset' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.a. - Test 1 (name: test1a-1_load_dataset, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'load_dataset' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'load_dataset' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test1a-2_load_dataset",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.572265Z",
     "start_time": "2025-01-17T16:10:39.545239Z"
    }
   },
   "source": [
    "# 1.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.a. - Test 2 (name: test1a-2_load_dataset, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'load_dataset' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "assert raw_dataset.shape == (211, 5) , 'Wrong shape for dataset dataframe'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'load_dataset' function implementation :-)\")\n",
    "raw_dataset.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.a. - Test 2 (name: test1a-2_load_dataset, points: 0.2)\n",
      "\t--->Testing the implementation of 'load_dataset' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'load_dataset' function implementation :-)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   customer_id  gender   age  annual_income  customer_score\n",
       "0     10001175  female  24.5           51.2            77.5\n",
       "1     10000426    male  38.0          278.4            63.5\n",
       "2     10001018  female  65.0          128.0            55.5\n",
       "3     10000825    male  18.5          236.8            10.5\n",
       "4     10000859  female  74.0          252.8            35.5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>customer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001175</td>\n",
       "      <td>female</td>\n",
       "      <td>24.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000426</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>278.4</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001018</td>\n",
       "      <td>female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000825</td>\n",
       "      <td>male</td>\n",
       "      <td>18.5</td>\n",
       "      <td>236.8</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000859</td>\n",
       "      <td>female</td>\n",
       "      <td>74.0</td>\n",
       "      <td>252.8</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.b. Remove missing values\n",
    "In this section you need to remove rows with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.b. Instructions\n",
    "<u>method name</u>: <b>remove_missing_values</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'remove_missing_values' function to return a copy of the dataframe, \n",
    "   in which you remove all rows with one or more missing values.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return dataset_cleaned</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.683256Z",
     "start_time": "2025-01-17T16:10:39.675120Z"
    }
   },
   "source": [
    "# 1.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.810146Z",
     "start_time": "2025-01-17T16:10:39.785004Z"
    }
   },
   "source": [
    "# 1.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def remove_missing_values(dataset):\n",
    "    return dataset.dropna()\n"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:39.941705Z",
     "start_time": "2025-01-17T16:10:39.928345Z"
    }
   },
   "source": [
    "# 1.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.070898Z",
     "start_time": "2025-01-17T16:10:40.058718Z"
    }
   },
   "source": [
    "# 1.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test1b-1_remove_missing_values",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.172499Z",
     "start_time": "2025-01-17T16:10:40.144588Z"
    }
   },
   "source": [
    "# 1.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.b. - Test 1 (name: test1b-1_remove_missing_values, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'remove_missing_values' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'remove_missing_values' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.b. - Test 1 (name: test1b-1_remove_missing_values, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'remove_missing_values' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'remove_missing_values' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test1b-2_remove_missing_values",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.339151Z",
     "start_time": "2025-01-17T16:10:40.218412Z"
    }
   },
   "source": [
    "# 1.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.b. - Test 2 (name: test1b-2_remove_missing_values, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'remove_missing_values' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "assert cln_dataset.shape == (207, 5), \"Wrong shape for dataset dataframe, after running 'remove_missing_values'\" \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'remove_missing_values' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.b. - Test 2 (name: test1b-2_remove_missing_values, points: 0.2)\n",
      "\t--->Testing the implementation of 'remove_missing_values' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'remove_missing_values' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.c. Remove duplicate rows\n",
    "In this section you need to remove duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.c. Instructions\n",
    "<u>method name</u>: <b>remove_duplicate_rows</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'remove_duplicate_rows' function to return a copy of the dataframe, \n",
    "   in which you remove all rows with duplicate rows.\n",
    "   Note: in case of duplicate rows, leave only the first occurrence.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return dataset_cleaned</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.452341Z",
     "start_time": "2025-01-17T16:10:40.443647Z"
    }
   },
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.469864Z",
     "start_time": "2025-01-17T16:10:40.452341Z"
    }
   },
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def remove_duplicate_rows(dataset):\n",
    "    return dataset.drop_duplicates()\n"
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.519225Z",
     "start_time": "2025-01-17T16:10:40.505358Z"
    }
   },
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_duplicate_rows(raw_dataset)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.556564Z",
     "start_time": "2025-01-17T16:10:40.550142Z"
    }
   },
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test1c-1_remove_duplicate_rows",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.616532Z",
     "start_time": "2025-01-17T16:10:40.594779Z"
    }
   },
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.c. - Test 1 (name: test1c-1_remove_duplicate_rows, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'remove_duplicate_rows' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_duplicate_rows(raw_dataset)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'remove_duplicate_rows' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.c. - Test 1 (name: test1c-1_remove_duplicate_rows, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'remove_duplicate_rows' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'remove_duplicate_rows' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test1c-2_remove_duplicate_rows",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.742328Z",
     "start_time": "2025-01-17T16:10:40.721977Z"
    }
   },
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.c. - Test 2 (name: test1c-2_remove_duplicate_rows, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'remove_duplicate_rows' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_duplicate_rows(raw_dataset)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "assert cln_dataset.shape == (204, 5), \"Wrong shape for dataset dataframe, after running 'remove_duplicate_rows'\" \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'remove_duplicate_rows' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.c. - Test 2 (name: test1c-2_remove_duplicate_rows, points: 0.1)\n",
      "\t--->Testing the implementation of 'remove_duplicate_rows' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'remove_duplicate_rows' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test1c-3_remove_duplicate_rows",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.774327Z",
     "start_time": "2025-01-17T16:10:40.757957Z"
    }
   },
   "source": [
    "# 1.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.c. - Test 3 (name: test1c-3_remove_duplicate_rows, points: 0.1)\")\n",
    "print (\"\\t--->Testing the implementation of 'remove_duplicate_rows' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "assert cln_dataset.shape == (200, 5), \"Wrong shape for dataset dataframe, after running 'remove_duplicate_rows'\" \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'remove_duplicate_rows' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.c. - Test 3 (name: test1c-3_remove_duplicate_rows, points: 0.1)\n",
      "\t--->Testing the implementation of 'remove_duplicate_rows' ...\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'remove_duplicate_rows' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.d. Transfer string to numeric\n",
    "In this section you need to string to numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.d. Instructions\n",
    "<u>method name</u>: <b>transfer_str_to_numeric_vals</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'transfer_str_to_numeric_vals' function to return a copy of the dataframe, \n",
    "   in which you transfer all the string values in the 'mall customer information' dataset to numeric.\n",
    "\n",
    "Notes: \n",
    "      * 'str_col' is the only column with string values. Transfer the unique string values to unique numeric values.\n",
    "      * You also need to remove the 'id_col_to_remove' column.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return dataset_transferred</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.828528Z",
     "start_time": "2025-01-17T16:10:40.814442Z"
    }
   },
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "raw_dataset.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   customer_id  gender   age  annual_income  customer_score\n",
       "0     10001175  female  24.5           51.2            77.5\n",
       "1     10000426    male  38.0          278.4            63.5\n",
       "2     10001018  female  65.0          128.0            55.5\n",
       "3     10000825    male  18.5          236.8            10.5\n",
       "4     10000859  female  74.0          252.8            35.5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>customer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001175</td>\n",
       "      <td>female</td>\n",
       "      <td>24.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000426</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>278.4</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001018</td>\n",
       "      <td>female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000825</td>\n",
       "      <td>male</td>\n",
       "      <td>18.5</td>\n",
       "      <td>236.8</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000859</td>\n",
       "      <td>female</td>\n",
       "      <td>74.0</td>\n",
       "      <td>252.8</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:40.946857Z",
     "start_time": "2025-01-17T16:10:40.931883Z"
    }
   },
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def transfer_str_to_numeric_vals(dataset,str_col,id_col_to_remove):\n",
    "    dataset = dataset.drop(columns=[id_col_to_remove])\n",
    "    unique_values = set(dataset[str_col])\n",
    "    mapping_dict = {value: index for index, value in enumerate(unique_values)}\n",
    "    dataset[str_col] = dataset[str_col].map(mapping_dict)\n",
    "    return dataset"
   ],
   "outputs": [],
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:41.069688Z",
     "start_time": "2025-01-17T16:10:41.052889Z"
    }
   },
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:41.546145Z",
     "start_time": "2025-01-17T16:10:41.522168Z"
    }
   },
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "num_dataset.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   gender   age  annual_income  customer_score\n",
       "0       1  24.5           51.2            77.5\n",
       "1       0  38.0          278.4            63.5\n",
       "2       1  65.0          128.0            55.5\n",
       "3       0  18.5          236.8            10.5\n",
       "4       1  74.0          252.8            35.5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>customer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>278.4</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>236.8</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>252.8</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1d-1_transfer_str_to_numeric_vals",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:41.786214Z",
     "start_time": "2025-01-17T16:10:41.750949Z"
    }
   },
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.d. - Test 1 (name: test1d-1_transfer_str_to_numeric_vals, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'transfer_str_to_numeric_vals' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.d. - Test 1 (name: test1d-1_transfer_str_to_numeric_vals, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'transfer_str_to_numeric_vals' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1d-2_transfer_str_to_numeric_vals",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.013382Z",
     "start_time": "2025-01-17T16:10:41.986918Z"
    }
   },
   "source": [
    "# 1.d.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.d. - Test 2 (name: test1d-2_transfer_str_to_numeric_vals, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert num_dataset.shape == (200, 4), \"Wrong shape for dataset dataframe, after running 'transfer_str_to_numeric_vals'\" \n",
    "assert list(num_dataset.select_dtypes(include=['number']).columns) == ['gender', 'age', 'annual_income', 'customer_score'], 'Wrong numeric columns '\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'transfer_str_to_numeric_vals' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.d. - Test 2 (name: test1d-2_transfer_str_to_numeric_vals, points: 0.2)\n",
      "\t--->Testing the implementation of 'transfer_str_to_numeric_vals' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'transfer_str_to_numeric_vals' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.e. Scale features\n",
    "In this section you will scale your dataset, using the 'StandardScaler' technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 1.e. Instructions\n",
    "<u>method name</u>: <b>scale_dataset</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'scale_dataset' function to return a copy of the dataframe, \n",
    "   in which you scale the features of the given 'dataset' in the 'mall customer information' dataset.\n",
    "\n",
    "Notes: \n",
    "     * Use the sklearn's StandardScaler for scaling.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return dataset_scaled</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.194875Z",
     "start_time": "2025-01-17T16:10:42.174013Z"
    }
   },
   "source": [
    "# 1.e.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.290489Z",
     "start_time": "2025-01-17T16:10:42.285810Z"
    }
   },
   "source": [
    "# 1.e.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def scale_dataset(dataset):\n",
    "    return StandardScaler().fit_transform(dataset)\n"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.431382Z",
     "start_time": "2025-01-17T16:10:42.405568Z"
    }
   },
   "source": [
    "# 1.e.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.460261Z",
     "start_time": "2025-01-17T16:10:42.431382Z"
    }
   },
   "source": [
    "# 1.e.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1e-1_scale_dataset",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.532712Z",
     "start_time": "2025-01-17T16:10:42.493871Z"
    }
   },
   "source": [
    "# 1.e.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.e. - Test 1 (name: test1e-1_scale_dataset, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'scale_dataset' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert scl_dataset.shape == (200, 4) , 'Wrong shape for dataset dataframe'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'scale_dataset' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.e. - Test 1 (name: test1e-1_scale_dataset, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'scale_dataset' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'scale_dataset' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test1e-2_scale_dataset",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.614846Z",
     "start_time": "2025-01-17T16:10:42.571453Z"
    }
   },
   "source": [
    "# 1.e.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 1.e. - Test 2 (name: test1e-2_scale_dataset, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'scale_dataset' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert list(np.round(scl_dataset.mean()+0.0001,2).values)==[0.0, 0.0, 0.0, 0.0], 'Wrong mean scaled values'\n",
    "assert list(np.round(scl_dataset.std()+0.0001,2).values) ==[1.0, 1.0, 1.0, 1.0], 'Wrong std scaled values'\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'scale_dataset' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1.e. - Test 2 (name: test1e-2_scale_dataset, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'scale_dataset' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'scale_dataset' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "<a id=\"data_exploration\"></a>\n",
    "## 2. Basic data exploration\n",
    "* Perform simple dataset exploration. It is suggested to use describe, info and a simple histogram for features' values\n",
    "  * You are also advised to plot a scatter plot\n",
    "  * You could see also the [explanation of the dataset above](#dataset_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.693291Z",
     "start_time": "2025-01-17T16:10:42.684770Z"
    }
   },
   "source": [
    "# --------------------------- RUN THIS CODE CELL (AFTER YOUR IMPLEMENTATION) -------------------------------------\n",
    "# Perform a simple dataset exploration. It is sugggested to use describe, info and a simple histogram for features' values\n",
    "# Transfer dataset's values to numeric ones.\n",
    "# Use the output of the exploration for next section.\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.707153Z",
     "start_time": "2025-01-17T16:10:42.693291Z"
    }
   },
   "source": [
    "# --------------------------- RUN THIS CODE CELL (AFTER YOUR IMPLEMENTATION) -------------------------------------\n",
    "# (OPTIONAL IMPLEMENTATION CELL) add some assitant code or use this\n",
    "# cell code for you exploration, if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 138
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "## 3. Simple call for clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 3.a. Call K-means algorithm\n",
    "Complete the 'perform_k_means' function to perform K-means clustering on the <br />\n",
    "    'mall customer information' dataset, using the given input parameters.<br />\n",
    "\n",
    "You need to return the trained model and the predicted associated clusters,<br /> \n",
    "    for the performed k-means clustering.<br />\n",
    "\n",
    "<u>Perform K-means clustering</u>:<br/>\n",
    "creare a k-means clustering model object (using `KMeans`), as following:\n",
    "* Set the `n_clusters`, `init`, `n_init` and `random_state` parameters.<br/>\n",
    "* Don't set any other parameters.<br/>\n",
    "    \n",
    "After you create the k-means model object, perform `fit` and `predict` to get the trained model and predicted values.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "<u>Input parameters</u>:<br />\n",
    "* dataset      - the dataset to run the K-means clustering on.\n",
    "* num_clusters - the number of clusters to set the 'n_clusters' parameter with \n",
    "* init_val     - the value to set the 'init' method parameter with.\n",
    "* n_init_val   - the vlue of the number of initializations to set the 'n_init' parameter with.\n",
    "* rand_state   - the random state, which you should set each of the K-means to run with.\n",
    "\n",
    "<u>Returned values</u>:<br />\n",
    "* model - the trained k-means model\n",
    "* predicted_vals - the predicted values, corresponding to each row in the given input dataset.\n",
    "\n",
    "-------------------\n",
    "\n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `model`, `predicted_vals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 3.a. Instructions\n",
    "<u>method name</u>: <b>perform_k_means</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'perform_k_means' function to perform K-means clustering on the \n",
    "    'mall customer information' dataset, using the given input parameters.\n",
    "\n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return model, predicted_vals</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.742698Z",
     "start_time": "2025-01-17T16:10:42.736202Z"
    }
   },
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.789492Z",
     "start_time": "2025-01-17T16:10:42.781142Z"
    }
   },
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def perform_k_means(dataset, num_clusters, init_val, n_init_val, rand_state):\n",
    "    kmeans_model = KMeans(n_clusters=num_clusters, init=init_val, n_init=n_init_val, random_state=rand_state)\n",
    "    kmeans_model.fit(dataset)\n",
    "    predicted_vals = kmeans_model.predict(dataset)\n",
    "    return kmeans_model, predicted_vals\n"
   ],
   "outputs": [],
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.876597Z",
     "start_time": "2025-01-17T16:10:42.823325Z"
    }
   },
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 3\n",
    "init_val ='k-means++'\n",
    "n_init_val = 5\n",
    "rand_state = 42\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "kmeans_model, predicted_vals = perform_k_means(scl_dataset, num_clusters, init_val, n_init_val, rand_state)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.911658Z",
     "start_time": "2025-01-17T16:10:42.905452Z"
    }
   },
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3a-1_perform_k_means",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:42.982612Z",
     "start_time": "2025-01-17T16:10:42.933891Z"
    }
   },
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.a. - Test 1 (name: test3a-1_perform_k_means, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "num_clusters = 3\n",
    "init_val ='k-means++'\n",
    "n_init_val = 5\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    kmeans_model, predicted_vals = perform_k_means(scl_dataset, num_clusters, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'perform_k_means' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.a. - Test 1 (name: test3a-1_perform_k_means, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'perform_k_means' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'perform_k_means' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 143
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3a-2_perform_k_means",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.055863Z",
     "start_time": "2025-01-17T16:10:43.007455Z"
    }
   },
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.a. - Test 2 (name: test3a-2_perform_k_means, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "num_clusters = 3\n",
    "init_val ='k-means++'\n",
    "n_init_val = 5\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    kmeans_model, predicted_vals = perform_k_means(scl_dataset, num_clusters, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert kmeans_model is not None and predicted_vals is not None, \"Error in returned values from the 'perform_k_means' function\"\n",
    "assert kmeans_model.n_clusters == num_clusters, \"Wrong value for the 'n_clusters' parameter\"\n",
    "assert kmeans_model.init == init_val, \"Wrong value for the 'init' parameter\"\n",
    "assert kmeans_model.n_init == n_init_val, \"Wrong value for the 'n_init' parameter\"\n",
    "assert kmeans_model.random_state == rand_state, \"Wrong value for the 'random_state' parameter\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'perform_k_means' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.a. - Test 2 (name: test3a-2_perform_k_means, points: 0.2)\n",
      "\t--->Testing the implementation of 'perform_k_means' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'perform_k_means' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3a-3_perform_k_means",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.160781Z",
     "start_time": "2025-01-17T16:10:43.110415Z"
    }
   },
   "source": [
    "# 3.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.a. - Test 3 (name: test3a-3_perform_k_means, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "num_clusters = 3\n",
    "init_val ='k-means++'\n",
    "n_init_val = 5\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    kmeans_model, predicted_vals = perform_k_means(scl_dataset, num_clusters, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "sse_score=kmeans_model.inertia_\n",
    "assert 470 <= sse_score <= 480, \"Wrong 'SSE' score for k-means clustering\"\n",
    "assert 80 <= pd.Series(predicted_vals).value_counts().values.max() <= 90 , \"Wrong maximum elements in clusrters\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'perform_k_means' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.a. - Test 3 (name: test3a-3_perform_k_means, points: 0.2)\n",
      "\t--->Testing the implementation of 'perform_k_means' ...\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'perform_k_means' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 3.b. Call Hierarchical Agglomerative Clustering\n",
    "Complete the 'perform_hierarchical_clustering' function to perform hierarchical agglomerative clustering on the <br />\n",
    "    'mall customer information' dataset, using the given input parameters.<br />\n",
    "\n",
    "You need to return the trained model and the predicted associated associated clusters,<br /> \n",
    "    for the performed hierarchical agglomerative clustering.<br />\n",
    "\n",
    "<u>Perform hierarchical agglomerative clustering</u>:<br/>\n",
    "Create an hierarchical agglomerative clustering (using AgglomerativeClustering) model object, as following:<br />\n",
    "* Set the `n_clusters` and `linkage` parameters.\n",
    "* Don't set any other parameters.\n",
    "    \n",
    "After you create the hierarchical agglomerative model object, perform `fit` and `predict` to get the trained model and predicted values.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "<u>Input parameters</u>:<br />\n",
    "* dataset      - the dataset to run the hierarchical agglomerative clustering on.\n",
    "* num_clusters - the number of clusters to set the 'n_clusters' parameter with \n",
    "* linkage_val  - the value to set the 'linkage' method parameter with.\n",
    "\n",
    "<u>Returned values</u>:<br />\n",
    "* model - the trained hierarchical agglomerative clustering model\n",
    "* predicted_vals - the predicted values, corresponding to each row in the given input dataset.\n",
    "\n",
    "-------------------\n",
    "\n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `model`, `predicted_vals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 3.b. Instructions\n",
    "<u>method name</u>: <b>perform_hierarchical_clustering</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'perform_hierarchical_clustering' function to perform hierarchical clustering \n",
    "   (AgglomerativeClustering) on the 'mall customer information' dataset, using the given input parameters.\n",
    "\n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return model, predicted_vals</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.212672Z",
     "start_time": "2025-01-17T16:10:43.198910Z"
    }
   },
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.247014Z",
     "start_time": "2025-01-17T16:10:43.240657Z"
    }
   },
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def perform_hierarchical_clustering(dataset, num_clusters, linkage_val):\n",
    "    model = AgglomerativeClustering(n_clusters=num_clusters, linkage=linkage_val)\n",
    "    predicted_vals = model.fit_predict(dataset)\n",
    "    return model, predicted_vals\n"
   ],
   "outputs": [],
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.298580Z",
     "start_time": "2025-01-17T16:10:43.277188Z"
    }
   },
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 3\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_val = 'single'\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "hierarchical_model, predicted_vals = perform_hierarchical_clustering(scl_dataset, num_clusters, linkage_val)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.327674Z",
     "start_time": "2025-01-17T16:10:43.323287Z"
    }
   },
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3b-1_perform_hierarchical_clustering",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.405937Z",
     "start_time": "2025-01-17T16:10:43.353487Z"
    }
   },
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.b. - Test 1 (name: test3b-1_perform_hierarchical_clustering, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_hierarchical_clustering' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "num_clusters = 3\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_val = 'single'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    hierarchical_model, predicted_vals = perform_hierarchical_clustering(scl_dataset, num_clusters, linkage_val)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'perform_hierarchical_clustering' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.b. - Test 1 (name: test3b-1_perform_hierarchical_clustering, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'perform_hierarchical_clustering' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'perform_hierarchical_clustering' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3b-2_perform_hierarchical_clustering",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.475223Z",
     "start_time": "2025-01-17T16:10:43.442585Z"
    }
   },
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.b. - Test 2 (name: test3b-2_perform_hierarchical_clustering, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_hierarchical_clustering' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "num_clusters = 3\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_val = 'single'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    hierarchical_model, predicted_vals = perform_hierarchical_clustering(scl_dataset, num_clusters, linkage_val)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert hierarchical_model is not None and predicted_vals is not None, \"Error in returned values from the 'perform_hierarchical_clustering' function\"\n",
    "assert hierarchical_model.n_clusters == num_clusters, \"Wrong value for the 'n_clusters' parameter\"\n",
    "assert hierarchical_model.linkage == linkage_val, \"Wrong value for the 'linkage' parameter\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'perform_hierarchical_clustering' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.b. - Test 2 (name: test3b-2_perform_hierarchical_clustering, points: 0.2)\n",
      "\t--->Testing the implementation of 'perform_hierarchical_clustering' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'perform_hierarchical_clustering' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3b-3_perform_hierarchical_clustering",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.551783Z",
     "start_time": "2025-01-17T16:10:43.517061Z"
    }
   },
   "source": [
    "# 3.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.b. - Test 3 (name: test3b-3_perform_hierarchical_clustering, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_hierarchical_clustering' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "num_clusters = 3\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_val = 'single'\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    hierarchical_model, predicted_vals = perform_hierarchical_clustering(scl_dataset, num_clusters, linkage_val)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert 100 <= pd.Series(predicted_vals).value_counts().values.max() <= 120 , \"Wrong maximum elements in clusrters\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'perform_hierarchical_clustering' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.b. - Test 3 (name: test3b-3_perform_hierarchical_clustering, points: 0.2)\n",
      "\t--->Testing the implementation of 'perform_hierarchical_clustering' ...\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'perform_hierarchical_clustering' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 3.c. Call Density-based spatial Clustering\n",
    "Complete the 'perform_density_based_clustering' function to perform density-based spatial clustering on the <br />\n",
    "    'mall customer information' dataset, using the given input parameters.<br />\n",
    "\n",
    "You need to return the trained model and the predicted associated associated clusters,<br /> \n",
    "    for the performed density-based spatial clustering.<br />\n",
    "\n",
    "<u>Perform density-based spatial clustering</u>:<br/>\n",
    "Create a density-based spatial clustering (using DBSCAN) model object, as following:<br />\n",
    "* Set the `eps` and `min_samples` parameters.\n",
    "* Don't set any other parameters.\n",
    "    \n",
    "After you create the density-based spatial model object, perform `fit` and `predict` to get the trained model and predicted values.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "<u>Input parameters</u>:<br />\n",
    "* dataset      - the dataset to run the density-based spatial clustering on.\n",
    "* epsilon_val - the maximum distance between two samples (epsilon) value to set the 'eps' parameter with \n",
    "* minimum_samples_val  - the minimum samples value to set the 'min_samples' parameter with.\n",
    "\n",
    "<u>Returned values</u>:<br />\n",
    "* model - the trained density-based spatial model\n",
    "* predicted_vals - the predicted values, corresponding to each row in the given input dataset.\n",
    "\n",
    "-------------------\n",
    "\n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `model`, `predicted_vals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 3.c. Instructions\n",
    "<u>method name</u>: <b>perform_density_based_clustering</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'perform_density_based_clustering' function to perform density-based spatial clustering\n",
    "   (DBSCAN) on the 'mall customer information' dataset, using the given input parameters.\n",
    "\n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return model, predicted_vals</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.589526Z",
     "start_time": "2025-01-17T16:10:43.578590Z"
    }
   },
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.665649Z",
     "start_time": "2025-01-17T16:10:43.657155Z"
    }
   },
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def perform_density_based_clustering(dataset, epsilon_val, minimum_samples_val):\n",
    "    model = DBSCAN(eps=epsilon_val, min_samples=minimum_samples_val)\n",
    "    predicted_vals = model.fit_predict(dataset)\n",
    "    return model, predicted_vals\n"
   ],
   "outputs": [],
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.692336Z",
     "start_time": "2025-01-17T16:10:43.672637Z"
    }
   },
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "epsilon_val = 10\n",
    "minimum_samples_val = 5\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "density_based_model, predicted_vals = perform_density_based_clustering(num_dataset, epsilon_val, minimum_samples_val)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.720131Z",
     "start_time": "2025-01-17T16:10:43.713438Z"
    }
   },
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3c-1_perform_density_based_clustering",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.771438Z",
     "start_time": "2025-01-17T16:10:43.744050Z"
    }
   },
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.c. - Test 1 (name: test3c-1_perform_density_based_clustering, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_density_based_clustering' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "epsilon_val = 10\n",
    "minimum_samples_val = 5\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    density_based_model, predicted_vals = perform_density_based_clustering(num_dataset, epsilon_val, minimum_samples_val)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'perform_density_based_clustering' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.c. - Test 1 (name: test3c-1_perform_density_based_clustering, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'perform_density_based_clustering' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'perform_density_based_clustering' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3c-2_perform_density_based_clustering",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.829891Z",
     "start_time": "2025-01-17T16:10:43.799274Z"
    }
   },
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.c. - Test 2 (name: test3c-2_perform_density_based_clustering, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_density_based_clustering' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "epsilon_val = 10\n",
    "minimum_samples_val = 5\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    density_based_model, predicted_vals = perform_density_based_clustering(num_dataset, epsilon_val, minimum_samples_val)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert density_based_model is not None and predicted_vals is not None, \"Error in returned values from the 'perform_density_based_clustering' function\"\n",
    "assert density_based_model.eps == epsilon_val, \"Wrong value for the 'eps' parameter\"\n",
    "assert density_based_model.min_samples == minimum_samples_val, \"Wrong value for the 'min_samples' parameter\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'perform_density_based_clustering' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.c. - Test 2 (name: test3c-2_perform_density_based_clustering, points: 0.2)\n",
      "\t--->Testing the implementation of 'perform_density_based_clustering' ...\n",
      "Good Job!\n",
      "You've passed the 2nd test for the 'perform_density_based_clustering' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test3c-3_perform_density_based_clustering",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.885399Z",
     "start_time": "2025-01-17T16:10:43.855584Z"
    }
   },
   "source": [
    "# 3.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 3.c. - Test 3 (name: test3c-3_perform_density_based_clustering, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'perform_density_based_clustering' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "\n",
    "epsilon_val = 10\n",
    "minimum_samples_val = 5\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    density_based_model, predicted_vals = perform_density_based_clustering(num_dataset, epsilon_val, minimum_samples_val)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert 150 <= pd.Series(predicted_vals).value_counts().values.max() <= 190 , \"Wrong maximum elements in clusrters\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'perform_density_based_clustering' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3.c. - Test 3 (name: test3c-3_perform_density_based_clustering, points: 0.2)\n",
      "\t--->Testing the implementation of 'perform_density_based_clustering' ...\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'perform_density_based_clustering' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "## 4. K-means hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 4.a. Find best initialization parameters for K-means\n",
    "Complete the 'get_best_init_params_for_k_means' function to find the best K-means permutation <br/>\n",
    "   of initialization parameters on the 'mall customer information' dataset. <br/>\n",
    "      \n",
    "**You need to return** the <u>best score</u> and the <u>best combination of the 'init' and 'n_init' parameters</u>,<br/>\n",
    "    using the K-means SSE  score, when running K-means with them on the 'mall customer information' dataset.<br/>\n",
    "\n",
    "<u>Note:</u> Use the kmeans_model.<u>inertia_</u> value, to get the SSE score, after you perform `fit` and `predict` <br /> \n",
    "the k-means model on the given dataset.\n",
    "    \n",
    "It is suggested to use the previously implemented `perform_k_means` function to get the the predicted cluster values.\n",
    "    \n",
    "------\n",
    "\n",
    "<u>Input parameters</u>:<br/>\n",
    "* dataset        - the dataset to run the K-means clustering on comparison.\n",
    "* num_clusters   - the number of clusters to set the 'n_clusters' parameter with \n",
    "* init_options   - a list of the possible 'init' methods for K-means score comparison.\n",
    "* n_init_options - a list of the possible number of initialization possibilities for K-means score comparison.\n",
    "* rand_state     - the random state, which you should set each of the K-means to run with.\n",
    "\n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `best_score`, `best_init_val`, `best_n_init_val`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 4.a. Instructions\n",
    "<u>method name</u>: <b>get_best_init_params_for_k_means</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'get_best_init_params_for_k_means' function to find the best K-means permutation \n",
    "   of initialization parameters on the 'mall customer information' dataset.\n",
    "\n",
    "You need to return the best combination of the 'init' and 'n_init' parameters, by the K-means SSE \n",
    "    score, when running K-means with them on the 'mall customer information' dataset.\n",
    "\n",
    "    Note: Use the kmeans_model.inertia_ value to get the SSE score, after you perform fit and predict\n",
    "          the k-means model on the given dataset.\n",
    "\n",
    "* It is suggested to use the previously implemented 'perform_k_means' function to get \n",
    "   the the predicted cluster values.\n",
    "   \n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_score, best_init_val, best_n_init_val</b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:43.922266Z",
     "start_time": "2025-01-17T16:10:43.912569Z"
    }
   },
   "source": [
    "# 4.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:11:21.951693Z",
     "start_time": "2025-01-17T16:11:21.941053Z"
    }
   },
   "source": [
    "## 4.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def get_best_init_params_for_k_means(dataset, num_clusters, init_options, n_init_options, rand_state):\n",
    "    best_score = np.inf\n",
    "    best_init_val = None\n",
    "    best_n_init_val = None\n",
    "    for init_val in init_options:\n",
    "        for n_init_val in n_init_options:\n",
    "            kmeans_model, _ = perform_k_means(\n",
    "                dataset, num_clusters, init_val, n_init_val, rand_state)\n",
    "            print(f\"Init: {init_val}, N_init: {n_init_val}, Score: {kmeans_model.inertia_}\")\n",
    "            if kmeans_model.inertia_ <= best_score:\n",
    "                best_score = kmeans_model.inertia_\n",
    "                best_init_val = init_val\n",
    "                best_n_init_val = n_init_val\n",
    "    return best_score, best_init_val, best_n_init_val\n"
   ],
   "outputs": [],
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:11:22.796535Z",
     "start_time": "2025-01-17T16:11:22.451001Z"
    }
   },
   "source": [
    "# 4.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 3\n",
    "init_options = ['random', 'k-means++']\n",
    "n_init_options = [1,5,10]\n",
    "rand_state = 42  \n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "best_score, best_init_val, best_n_init_val = get_best_init_params_for_k_means(scl_dataset, num_clusters, init_options, n_init_options, rand_state)           \n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: random, N_init: 1, Score: 494.82948928430704\n",
      "Init: random, N_init: 5, Score: 489.5731167221885\n",
      "Init: random, N_init: 10, Score: 476.7732065607644\n",
      "Init: k-means++, N_init: 1, Score: 476.78755441351586\n",
      "Init: k-means++, N_init: 5, Score: 476.78755441351586\n",
      "Init: k-means++, N_init: 10, Score: 476.78755441351586\n"
     ]
    }
   ],
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:44.246870Z",
     "start_time": "2025-01-17T16:10:44.238317Z"
    }
   },
   "source": [
    "# 4.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "print(f\"Best score: {best_score}, Best init: {best_init_val}, Best n_init: {best_n_init_val}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 476.7732065607644, Best init: random, Best n_init: 10\n"
     ]
    }
   ],
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4a-1_get_best_init_params_for_k_means",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:44.412598Z",
     "start_time": "2025-01-17T16:10:44.262312Z"
    }
   },
   "source": [
    "# 4.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.a. - Test 1 (name: test4a-1_get_best_init_params_for_k_means, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_init_params_for_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 3\n",
    "init_options = ['random', 'k-means++']\n",
    "n_init_options = [1,5,10]\n",
    "rand_state = 42\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_init_val, best_n_init_val = get_best_init_params_for_k_means(scl_dataset, num_clusters, init_options, n_init_options, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'get_best_init_params_for_k_means' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4.a. - Test 1 (name: test4a-1_get_best_init_params_for_k_means, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'get_best_init_params_for_k_means' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'get_best_init_params_for_k_means' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4a-2_get_best_init_params_for_k_means",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:10:57.645799Z",
     "start_time": "2025-01-17T16:10:55.362244Z"
    }
   },
   "source": [
    "# 4.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.a. - Test 2 (name: test4a-2_get_best_init_params_for_k_means, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_init_params_for_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 3\n",
    "init_options = ['random', 'k-means++']\n",
    "n_init_options = [1,5,10]\n",
    "rand_state = 42\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_init_val, best_n_init_val = get_best_init_params_for_k_means(scl_dataset, num_clusters, init_options, n_init_options, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert best_init_val == 'k-means++', \"Wrong best value for the 'best_init_val' parameter\"\n",
    "    \n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'get_best_init_params_for_k_means' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4.a. - Test 2 (name: test4a-2_get_best_init_params_for_k_means, points: 0.2)\n",
      "\t--->Testing the implementation of 'get_best_init_params_for_k_means' ...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Wrong best value for the 'best_init_val' parameter",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[165], line 27\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTry fixing your implementation\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m best_init_val \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk-means++\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong best value for the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_init_val\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m parameter\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGood Job!\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mYou\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mve passed the 2nd test for the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mget_best_init_params_for_k_means\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m function implementation :-)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Wrong best value for the 'best_init_val' parameter"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4a-3_get_best_init_params_for_k_means",
     "locked": true,
     "points": "0.3",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:06:55.009413Z",
     "start_time": "2025-01-17T16:06:54.780774Z"
    }
   },
   "source": [
    "# 4.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.a. - Test 3 (name: test4a-3_get_best_init_params_for_k_means, points: 0.3)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_init_params_for_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 3\n",
    "init_options = ['random', 'k-means++']\n",
    "n_init_options = [1,5,10]\n",
    "rand_state = 42\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_init_val, best_n_init_val = get_best_init_params_for_k_means(scl_dataset, num_clusters, init_options, n_init_options, rand_state)\n",
    "    \n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert 474<= best_score <= 479, \"Wrong best score for initialization parameters\"\n",
    "\n",
    "print ('---> Best combination: init: %r, n_init: %r;\\tbest score: %4.2f' %(best_init_val, best_n_init_val, best_score))\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'get_best_init_params_for_k_means' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4.a. - Test 3 (name: test4a-3_get_best_init_params_for_k_means, points: 0.3)\n",
      "\t--->Testing the implementation of 'get_best_init_params_for_k_means' ...\n",
      "---> Best combination: init: 'random', n_init: 10;\tbest score: 476.77\n",
      "Good Job!\n",
      "You've passed the 3rd test for the 'get_best_init_params_for_k_means' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 4.b. Compare different number of clusters\n",
    "Complete the 'compare_num_of_clusters' function to compare between the performance of <br/>\n",
    "   K-means on the 'mall customer information' dataset, using different values for the <br/>\n",
    "   'n_clusters' parameters. <br/>\n",
    "      \n",
    "**You need to return** a python list of the scores, containing corresponding a score for each <br />\n",
    "   `num_cluster_option` number of cluster option, using the K-means SSE  score,<br/>\n",
    "    when running K-means with them on the 'mall customer information' dataset.<br/>\n",
    "\n",
    "<u>Note:</u> Use the kmeans_model.<u>inertia_</u> value to get the SSE score, after you perform `fit` and `predict` <br />\n",
    "         the k-means model on the given dataset.\n",
    "\n",
    "It is suggested to use the previously implemented `perform_k_means` function to get the the predicted cluster values.\n",
    "\n",
    "------\n",
    "\n",
    "<u>Input parameters</u>:<br/>\n",
    "* dataset            - the dataset to run the K-means clustering on comparison.\n",
    "* num_cluster_options-  a list of the possible number of clusters values, to set the 'n_clusters' parameter with.\n",
    "* init_val        - the value to set the 'init' method parameter with.\n",
    "* n_init_val - the vlue of the number of initializations to set the 'n_init' parameter with.\n",
    "* rand_state     - the random state, which you should set each of the K-means to run with.\n",
    "\n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `lst_scores`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 4.b. Instructions\n",
    "<u>method name</u>: <b>compare_num_of_clusters</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'compare_num_of_clusters' function to compare between the performance of\n",
    "   K-means on the 'mall customer information' dataset, using different values for the\n",
    "   'n_clusters' parameters.\n",
    "\n",
    "You need to return a python list of the scores, containing corresponding a score for each\n",
    "    num_cluster_option number of cluster option, using the K-means SSE score,\n",
    "    when running K-means with them on the 'mall customer information' dataset.\n",
    "\n",
    "Note: Use the kmeansmodel.inertia value to get the SSE score, after you perform fit and predict\n",
    "     the k-means model on the given dataset.\n",
    "\n",
    "* It is suggested to use the previously implemented 'perform_k_means' function to get the the predicted cluster values.\n",
    "\n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return lst_scores</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:08:25.831350Z",
     "start_time": "2025-01-17T16:08:25.822845Z"
    }
   },
   "source": [
    "# 4.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def compare_number_of_clusters(dataset, num_cluster_options, init_val, n_init_val, rand_state):\n",
    "    lst_scores = []\n",
    "    for num_clusters in num_cluster_options:\n",
    "        kmeans_model, _ = perform_k_means(\n",
    "            dataset, num_clusters, init_val, n_init_val, rand_state)\n",
    "        lst_scores.append(kmeans_model.inertia_)\n",
    "    return lst_scores\n"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:08:26.705619Z",
     "start_time": "2025-01-17T16:08:26.597100Z"
    }
   },
   "source": [
    "# 4.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters_options = [3,4,5,6,7,8,9]\n",
    "init_val = 'k-means++'\n",
    "n_init_val = 1\n",
    "rand_state = 42\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "scores = compare_number_of_clusters(scl_dataset, num_clusters_options, init_val, n_init_val, rand_state)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:08:27.482913Z",
     "start_time": "2025-01-17T16:08:27.478638Z"
    }
   },
   "source": [
    "# 4.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4b-1_compare_number_of_clusters",
     "locked": true,
     "points": "0.3",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:08:28.130750Z",
     "start_time": "2025-01-17T16:08:27.939494Z"
    }
   },
   "source": [
    "# 4.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.b. - Test 1 (name: test4b-1_compare_number_of_clusters, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'compare_number_of_clusters' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters_options = [3,4,5,6,7,8,9]\n",
    "init_val = 'k-means++'\n",
    "n_init_val = 1\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    scores = compare_number_of_clusters(scl_dataset, num_clusters_options, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'compare_number_of_clusters' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4.b. - Test 1 (name: test4b-1_compare_number_of_clusters, points: 0.1) - Sanity\n",
      "\t--->Testing the implementation of 'compare_number_of_clusters' ...\n",
      "Good Job!\n",
      "You've passed the 1st test for the 'compare_number_of_clusters' function implementation :-)\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4b-2_compare_number_of_clusters",
     "locked": true,
     "points": "0.3",
     "solution": false
    },
    "editable": false,
    "deletable": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:08:29.345188Z",
     "start_time": "2025-01-17T16:08:29.142760Z"
    }
   },
   "source": [
    "# 4.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.b. - Test 2 (name: test4b-2_compare_number_of_clusters, points: 0.3)\")\n",
    "print (\"\\t--->Testing the implementation of 'compare_number_of_clusters' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters_options = [1,2,3,4,5,6,7,8,9]\n",
    "init_val = 'k-means++'\n",
    "n_init_val = 1\n",
    "rand_state = 42\n",
    "\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    scores_2_3 = compare_number_of_clusters(scl_dataset.iloc[:,[2,3]], num_clusters_options, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert 132 <= np.mean(scores_2_3) <= 137, \"Wrong average SSE value\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'compare_number_of_clusters' function implementation :-)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4.b. - Test 2 (name: test4b-2_compare_number_of_clusters, points: 0.3)\n",
      "\t--->Testing the implementation of 'compare_number_of_clusters' ...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Wrong average SSE value",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[104], line 29\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTry fixing your implementation\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;241m132\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(scores_2_3) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m137\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong average SSE value\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGood Job!\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mYou\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mve passed the 2nd test for the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcompare_number_of_clusters\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m function implementation :-)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Wrong average SSE value"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "test4b-3_compare_number_of_clusters",
     "locked": true,
     "points": "0.3",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# --------------------------- RUN THIS CODE CELL  -------------------------------------\n",
    "# The Elbow Method:\n",
    "scores_2_3 = compare_number_of_clusters(scl_dataset.iloc[:,[2,3]], num_clusters_options, init_val, n_init_val, rand_state)\n",
    "\n",
    "plt.plot(num_clusters_options,scores_2_3)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 4.c.Select the best K-means number of clusters value\n",
    "Complete the 'get_best_num_of_clusters_for_k_means' function to find the best  <br/>\n",
    "    number of clusters for k-means clustering, on the 'mall customer information' dataset. <br/>\n",
    "      \n",
    "**You need to return** the <u>best score</u> and the <u>best value 'n_clusters' parameter</u>,<br/>\n",
    "    using the silhouette score, when running K-means on the 'mall customer information' dataset.<br/>\n",
    "\n",
    "<u>Note:</u> Use the `silhouette_score` to get the score on input dataset and the predicted values returned <br />\n",
    "        after performing `fit` and `predict` for the  k-means model on the given dataset.<br /> \n",
    " \n",
    "It is suggested to use the previously implemented `perform_k_means` function to get the the predicted cluster values.\n",
    "\n",
    "------\n",
    "\n",
    "<u>Input parameters</u>:<br />\n",
    "* dataset      - the dataset to run the K-means clustering on.\n",
    "* num_cluster_options -  a list of the possible number of clusters values, to set the 'n_clusters' parameter with.\n",
    "* init_val     - the value to set the 'init' method parameter with.\n",
    "* n_init_val   - the vlue of the number of initializations to set the 'n_init' parameter with.\n",
    "* rand_state   - the random state, which you should set each of the K-means to run with.\n",
    "\n",
    "<u>Returned values</u>:<br />\n",
    "* best_score - the best silhouette score\n",
    "* num_clusters - the best number of clusters value.\n",
    "\n",
    "------\n",
    "    \n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `best_score`, `num_clusters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 4.c. Instructions\n",
    "<u>method name</u>: <b>get_best_num_of_clusters_for_k_means</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'get_best_num_of_clusters_for_k_means' function to find the best\n",
    "    number of clusters for k-means clustering, on the 'mall customer information' dataset.\n",
    "\n",
    "You need to return the best score and the best value 'n_clusters' parameter,\n",
    "    using the silhouette score, when running K-means on the 'mall customer information' dataset.\n",
    "\n",
    "Use the silhouette_score to get the score on input dataset and the predicted values returned\n",
    "    after performing fit and predict for the k-means model on the given dataset.\n",
    "\n",
    "* It is suggested to use the previously implemented 'perform_k_means' function to get \n",
    "   the the predicted cluster values.\n",
    "\n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_score, num_clusters</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def get_best_num_of_clusters_for_k_means(dataset, num_cluster_options, init_val, n_init_val, rand_state):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters_options = [2,3,4,5,6,7,8,9]\n",
    "init_val = 'k-means++'\n",
    "n_init_val = 1\n",
    "rand_state = 42\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "best_score, best_num_clusters = get_best_num_of_clusters_for_k_means(scl_dataset.iloc[:,[2,3]], num_clusters_options, init_val, n_init_val, rand_state)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4c-1_get_best_num_of_clusters_for_k_means",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 4.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.c. - Test 1 (name: test4c-1_get_best_num_of_clusters_for_k_means, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_num_of_clusters_for_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters_options = [2,3,4,5,6,7,8,9]\n",
    "init_val = 'k-means++'\n",
    "n_init_val = 1\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    score, num_clusters = get_best_num_of_clusters_for_k_means(scl_dataset.iloc[:,[2,3]], num_clusters_options, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'get_best_num_of_clusters_for_k_means' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4c-2_get_best_num_of_clusters_for_k_means",
     "locked": true,
     "points": "0.3",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 4.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.c. - Test 2 (name: test4c-2_get_best_num_of_clusters_for_k_means, points: 0.3)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_num_of_clusters_for_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters_options = [2,3,4,5,6,7,8,9]\n",
    "init_val = 'k-means++'\n",
    "n_init_val = 1\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_num_clusters = get_best_num_of_clusters_for_k_means(scl_dataset.iloc[:,[2,3]], num_clusters_options, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert best_num_clusters == 6, \"Wrong value for best 'n_clusters' value\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'get_best_num_of_clusters_for_k_means' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test4c-3_get_best_num_of_clusters_for_k_means",
     "locked": true,
     "points": "0.3",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 4.c.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 4.c. - Test 3 (name: test4c-3_get_best_num_of_clusters_for_k_means, points: 0.3)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_num_of_clusters_for_k_means' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters_options = [2,3,4,5,6,7,8,9]\n",
    "init_val = 'k-means++'\n",
    "n_init_val = 1\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_num_clusters = get_best_num_of_clusters_for_k_means(scl_dataset.iloc[:,[2,3]], num_clusters_options, init_val, n_init_val, rand_state)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert 0.51<= best_score <= 0.56, \"Wrong best silhouette score\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'get_best_num_of_clusters_for_k_means' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "## 5. Hierarchical agglomerative clustering and DBSCAN hyperparameters\n",
    "In this section you will perform the following:\n",
    "* Find the best 'linkage' method for hierarchical agglomerative clustering\n",
    "* Find the best combination of 'eps' and 'min_samples' values for DBSCAN clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 5.a. Find best 'linkage' method for hierarchical agglomerative clustering\n",
    "Complete the 'get_best_linkage_method' function to find the best linkage method for <br/>\n",
    "   hierarchical agglomerative clustering on the 'mall customer information' dataset.<br/>\n",
    "    \n",
    "**You need to return** the <u>best score</u> and the <u>best value of the 'linkage' parameter</u>,<br/>\n",
    "    using the silhouette score, when running hierarchical agglomerative clustering<br/>\n",
    "        on the 'mall customer information' dataset.<br/>\n",
    "\n",
    "<u>Note:</u> Use the `silhouette_score` to get the score on input dataset and the predicted values returned <br />\n",
    "        after performing `fit` and `predict` for the hierarchical agglomerative clustering model <br />\n",
    "        on the given dataset.<br /> \n",
    "\n",
    "It is suggested to use the previously implemented `perform_hierarchical_clustering` function to get the the predicted cluster values.\n",
    "\n",
    "------\n",
    "\n",
    "<u>Input parameters</u>:<br/>\n",
    "* dataset        - the dataset to run the K-means clustering on comparison.\n",
    "* num_clusters    - the number of clusters to set the 'n_clusters' parameter with \n",
    "* linkage_options - a list of the possible 'linkage' methods for K-means score comparison.\n",
    "\n",
    "<u>Returned values</u>:<br />\n",
    "* best_score         - the best silhouette score\n",
    "* best_linkage_mehod - the best linkage method.\n",
    "\n",
    "------\n",
    "    \n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `best_score`, `best_linkage_mehod`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "source": [
    "### 5.a. Instructions\n",
    "<u>method name</u>: <b>get_best_linkage_method</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'get_best_linkage_method' function to find the best linkage method for\n",
    "      hierarchical agglomerative clustering on the 'mall customer information' dataset.\n",
    "\n",
    "You need to return the best score and the best value of the 'linkage' parameter,\n",
    "      using the silhouette score, when running hierarchical agglomerative clustering\n",
    "      on the 'mall customer information' dataset.\n",
    "\n",
    "Note: Use the silhouette_score to get the score on input dataset and the predicted values returned\n",
    "     after performing fit and predict for the hierarchical agglomerative clustering model\n",
    "     on the given dataset.\n",
    "\n",
    "It is suggested to use the previously implemented 'perform_hierarchical_clustering' function to get the the predicted cluster values.\n",
    "\n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_score, best_linkage</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def get_best_linkage_method(dataset, num_clusters, linkage_options):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 5\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_options = ['single', 'complete', 'average', 'ward']\n",
    "rand_state = 42\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "best_score, best_linkage_method = get_best_linkage_method(scl_dataset.iloc[:,[2,3]], num_clusters, linkage_options)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test5a-1_get_best_linkage_method",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 5.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 5.a. - Test 1 (name: test5a-1_get_best_linkage_method, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_linkage_method' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 5\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_options = ['single', 'complete', 'average', 'ward']\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_linkage_method = get_best_linkage_method(scl_dataset.iloc[:,[2,3]], num_clusters, linkage_options)\n",
    "\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'get_best_linkage_method' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test5a-2_get_best_linkage_method",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 5.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 5.a. - Test 2 (name: test5a-2_get_best_linkage_method, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_linkage_method' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 5\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_options = ['single', 'complete', 'average', 'ward']\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_linkage_method = get_best_linkage_method(scl_dataset.iloc[:,[2,3]], num_clusters, linkage_options)\n",
    "\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert best_linkage_method == 'ward', \"Wrong value for best 'linkage' value\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'get_best_linkage_method' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test5a-3_get_best_linkage_method",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 5.a.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 5.a. - Test 3 (name: test5a-3_get_best_linkage_method, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_linkage_method' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "num_clusters = 5\n",
    "# linkage_val one of the following: ward, complete, average, single\n",
    "linkage_options = ['single', 'complete', 'average', 'ward']\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    scl_dataset = pd.DataFrame(scale_dataset(num_dataset),index=num_dataset.index,columns=num_dataset.columns)\n",
    "    best_score, best_linkage_method = get_best_linkage_method(scl_dataset.iloc[:,[2,3]], num_clusters, linkage_options)\n",
    "\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert 0.54 <= best_score <= 0.57, \"Wrong best silhouette score\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'get_best_linkage_method' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b. Find the best combination of 'eps' and 'min_samples' values for DBSCAN clustering\n",
    "Complete the 'get_best_params_for_dbscan' function to find the best parameter permutation <br/>\n",
    "   for running density based clustering (DBSCAN) on the 'mall customer information' dataset. <br/>\n",
    "      \n",
    "**You need to return** the <u>best score</u> and the <u>best combination of the<br/>\n",
    "    'eps' and 'min_samples' values for DBSCAN clustering, using the silhouette score, <br/>\n",
    "         when running density based clustering on the 'mall customer information' dataset.<br/>\n",
    "\n",
    "<u>Note:</u> Use the `silhouette_score` to get the score on input dataset and the predicted values returned <br />\n",
    "        after performing `fit` and `predict` for the density based clustering model <br />\n",
    "        on the given dataset.<br />     \n",
    "    \n",
    "It is suggested to use the previously implemented `perform_density_based_clustering` function to get the the predicted cluster values.\n",
    "    \n",
    "------\n",
    "\n",
    "<u>Input parameters</u>:<br/>\n",
    "* dataset        - the dataset to run the K-means clustering on comparison.\n",
    "* eps_options    - a list of the possible 'eps' values\n",
    "* min_samples_options - a list of the possible 'min_samples' methods for values.\n",
    "\n",
    "<u>Returned values</u>:<br />\n",
    "* best_score       - the best silhouette score\n",
    "* best_eps         - the best `eps` value\n",
    "* best_min_samples - the best `min_samples` value\n",
    "    \n",
    "<u>The return statement should look similar to the following statement</u>:<br />\n",
    "return `best_score`, `best_eps`, `best_min_samples`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b. Instructions\n",
    "<u>method name</u>: <b>get_best_params_for_dbscan</b>\n",
    "<pre>The following is expected:\n",
    "--- Complete the 'get_best_params_for_dbscan' function to find the best parameter permutation\n",
    "     for running density based clustering (DBSCAN) on the 'mall customer information' dataset.\n",
    "\n",
    "You need to return the best score and the best combination of the\n",
    "    'eps' and 'min_samples' values for DBSCAN clustering, using the silhouette score,\n",
    "    when running density based clustering on the 'mall customer information' dataset.\n",
    "\n",
    "Note: Use the silhouette_score to get the score on input dataset and the predicted values returned\n",
    "     after performing fit and predict for the density based clustering model on the given dataset.\n",
    "\n",
    "It is suggested to use the previously implemented 'perform_density_based_clustering' function to\n",
    "     get the the predicted cluster values.\n",
    "\n",
    "For more information, see the explanation above.\n",
    "</pre>\n",
    "<hr>\n",
    "The return statement should look similar to the following statement:<br />\n",
    "<b>return best_score, best_eps, best_min_samples</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ASSISTANCE TO ANSWER \n",
    "# ---- Add assistance code here IF NEEDED:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: ANSWER \n",
    "\n",
    "def get_best_params_for_dbscan(dataset, eps_options, min_samples_options):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# Use the following code to test your implementation:\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "eps_options = [10,11,12]\n",
    "min_samples_options = [4,5,6,7,8]\n",
    "rand_state = 42\n",
    "raw_dataset = load_dataset(file_name)\n",
    "cln_dataset = remove_missing_values(raw_dataset)\n",
    "cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "# subset of dataset:\n",
    "num_dataset_2_3 = num_dataset.iloc[:,[2,3]]\n",
    "# no scaling here \n",
    "best_score, best_eps, best_min_samples = get_best_params_for_dbscan(num_dataset_2_3, eps_options, min_samples_options)\n",
    "# --- add additional code to check your code if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run after implementation, if used)\n",
    "# === CODE TYPE: SELF TESTING\n",
    "# ---- Add your additional tests here if needed:\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test5b-1_get_best_params_for_dbscan",
     "locked": true,
     "points": "0.1",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 5.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 5.b. - Test 1 (name: test5b-1_get_best_params_for_dbscan, points: 0.1) - Sanity\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_params_for_dbscan' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "eps_options = [10,11,12]\n",
    "min_samples_options = [4,5,6,7,8]\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    # subset of dataset:\n",
    "    num_dataset_2_3 = num_dataset.iloc[:,[2,3]]\n",
    "    # no scaling here \n",
    "    best_score, best_eps, best_min_samples = get_best_params_for_dbscan(num_dataset_2_3, eps_options, min_samples_options)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 1st test for the 'get_best_params_for_dbscan' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test5b-2_get_best_params_for_dbscan",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 5.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 5.b. - Test 2 (name: test5b-2_get_best_params_for_dbscan, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_params_for_dbscan' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "eps_options = [10,11,12]\n",
    "min_samples_options = [4,5,6,7,8]\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    # subset of dataset:\n",
    "    num_dataset_2_3 = num_dataset.iloc[:,[2,3]]\n",
    "    # no scaling here \n",
    "    best_score, best_eps, best_min_samples = get_best_params_for_dbscan(num_dataset_2_3, eps_options, min_samples_options)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "\n",
    "assert best_eps == 12, \"Wrong value for best 'eps' value\"\n",
    "assert best_min_samples == 4, \"Wrong value for best 'min_samples' value\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 2nd test for the 'get_best_params_for_dbscan' function implementation :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test5b-3_get_best_params_for_dbscan",
     "locked": true,
     "points": "0.2",
     "solution": false
    },
    "editable": false,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 5.b.\n",
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# --------  (run only)\n",
    "# === CODE TYPE: GRADED TEST \n",
    "\n",
    "print (\"Part 5.b. - Test 3 (name: test5b-3_get_best_params_for_dbscan, points: 0.2)\")\n",
    "print (\"\\t--->Testing the implementation of 'get_best_params_for_dbscan' ...\")\n",
    "\n",
    "file_name = '.' + os.sep + 'data' + os.sep + 'mall_customer_information.csv'\n",
    "eps_options = [10,11,12]\n",
    "min_samples_options = [4,5,6,7,8]\n",
    "rand_state = 42\n",
    "\n",
    "try:\n",
    "    raw_dataset = load_dataset(file_name)\n",
    "    cln_dataset = remove_missing_values(raw_dataset)\n",
    "    cln_dataset = remove_duplicate_rows(cln_dataset)\n",
    "    num_dataset = transfer_str_to_numeric_vals(cln_dataset, 'gender', 'customer_id')\n",
    "    # subset of dataset:\n",
    "    num_dataset_2_3 = num_dataset.iloc[:,[2,3]]\n",
    "    # no scaling here \n",
    "    best_score, best_eps, best_min_samples = get_best_params_for_dbscan(num_dataset_2_3, eps_options, min_samples_options)\n",
    "except Exception as e:\n",
    "    print ('You probably have a syntax error, we got the following exception:')\n",
    "    print ('\\tError Message:', str(e))\n",
    "    print ('Try fixing your implementation')\n",
    "    raise \n",
    "    \n",
    "assert 0.24<= best_score <= 0.249, \"Wrong best silhouette score\"\n",
    "\n",
    "print (\"Good Job!\\nYou've passed the 3rd test for the 'get_best_params_for_dbscan' function implementation :-)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
